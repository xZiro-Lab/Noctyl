# Noctyl

<p align="center">
  <img src="https://media.giphy.com/media/3o7abKhOpu0NwenH3O/giphy.gif" width="120" alt="owl" />
</p>

```
  _   ___     (o o)   _   _
 | \ | _ \   (  V  ) | | | |
 |  \| __/    |~~~|  | |_| |
 |_| |_|      +---+   \__/
 N   o   c     t     y   l
    
```

**Static Token Usage Estimator for Multi-Agent AI Workflows**

Noctyl is a static analysis tool that **estimates token usage and cost for multi-agent AI workflows *before execution***.  
It analyzes a code repository, constructs a workflow graph, and produces structured reports that can be consumed by humans *and* AI assistants (Claude, Codex, Copilot, Cursor).

> Noctyl does **not** execute agents, call LLM APIs, or burn tokens.  
> It provides **pre-run intelligence** for cost, safety, and efficiency.

---

## Why Noctyl?

Agentic systems often fail silently due to:

- Unbounded loops
- Prompt and memory explosion
- Hidden retry costs
- Poor agent decomposition

Noctyl answers:

- *How many tokens will this workflow burn before I run it?*
- *Where does token growth originate?*
- *Which agents are cost hotspots?*
- *What can be optimized pre-deployment?*

---

## Core Capabilities

- ğŸŒ **Workflow Graph Extraction**
  - Builds a directed semantic graph from agentic codebases
  - Captures agents, tools, loops, retries, and memory interactions

- ğŸ“Š **Enriched workflow graph (Phase 2)**
  - **GraphAnalyzer** and **ExecutionModel** for control-flow, cycles, metrics, node annotations, and structural risks
  - Optional `enriched=True` pipeline output (schema 2.0); see `docs/phase/phase2.md` and `docs/flow-diagrams.md`

- ğŸ“ **Static Token Estimation (Phase 3)**
  - Token envelope estimation (min/expected/max ranges)
  - Node-level token signatures with prompt size detection
  - Model profiles for user-declared assumptions
  - Cost envelope computation for workflows, nodes, and paths
  - Optional `estimate=True` pipeline output (schema 3.0); see `docs/phase/phase3.md` and `docs/flow-diagrams.md`

- âš ï¸ **Risk Detection**
  - Unbounded loops
  - Recursive agent calls
  - Memory writes inside loops
  - Tool output amplification

- ğŸ¤– **AI-Assistant Integration**
  - Generates structured context for Claude, Codex, Copilot, Cursor
  - No API keys required
  - File-based, assistant-agnostic design

---

## What Noctyl Is NOT

- âŒ Not a runtime token monitor
- âŒ Not a tracing or observability tool
- âŒ Not an LLM wrapper
- âŒ Not tied to any single agent framework

Noctyl runs **before execution**, not during or after.

---

## Installation

### One-line installer (recommended)

```bash
curl -fsSL https://raw.githubusercontent.com/xZiro-Lab/Noctyl/main/install.sh | bash
```

### CLI Usage

After installation, use the `noctyl estimate` command to estimate token usage:

```bash
# Basic usage (default profile)
noctyl estimate ./my_project

# With custom model profile
noctyl estimate ./my_project --profile profiles/gpt-4o.yaml

# Save output to file
noctyl estimate ./my_project --output estimates.json

# With profile and output file
noctyl estimate ./my_project --profile profiles/gpt-4o.yaml --output estimates.json
```

**Profile File Format (YAML):**
```yaml
# Single profile format
name: gpt-4o
expansion_factor: 1.2
output_ratio: 0.6
pricing:
  input_per_1k: 0.005
  output_per_1k: 0.015

# Multi-profile format (first profile used)
model_profiles:
  gpt-4o:
    expansion_factor: 1.2
    output_ratio: 0.6
    pricing:
      input_per_1k: 0.005
      output_per_1k: 0.015
```

**Output:** The CLI outputs JSON with schema 3.0 format, including token estimates, node signatures, per-node and per-path envelopes, and warnings. See `docs/phase/phase3.md` for details.

---

## Project structure

```
noctyl/
â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ install.sh
â”œâ”€â”€ .gitignore
â”‚
â”œâ”€â”€ noctyl/                         # Core package
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ ingestion/                  # Repo scanning, detection & extraction (Phase 1)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ pipeline.py             # run_pipeline_on_directory (Phase 1 + Phase 2)
â”‚   â”‚   â”œâ”€â”€ repo_scanner.py         # discover_python_files + default ignores
â”‚   â”‚   â”œâ”€â”€ langgraph_detector.py   # has_langgraph_import / file_contains_langgraph
â”‚   â”‚   â”œâ”€â”€ stategraph_tracker.py   # track StateGraph instances per file
â”‚   â”‚   â”œâ”€â”€ node_extractor.py       # extract add_node calls per graph
â”‚   â”‚   â”œâ”€â”€ edge_extractor.py       # extract add_edge / add_conditional_edges / entry points
â”‚   â”‚   â””â”€â”€ receiver_resolution.py  # alias map + resolve receiver to tracked graph
â”‚   â”‚
â”‚   â”œâ”€â”€ graph/                      # Data model, serialization & visualization
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ graph.py                # WorkflowGraph, build_workflow_graph, workflow_graph_to_dict
â”‚   â”‚   â”œâ”€â”€ nodes.py                # ExtractedNode dataclass
â”‚   â”‚   â”œâ”€â”€ edges.py                # ExtractedEdge, ExtractedConditionalEdge dataclasses
â”‚   â”‚   â”œâ”€â”€ execution_model.py      # ExecutionModel, DetectedCycle, StructuralMetrics, etc. (Phase 2)
â”‚   â”‚   â””â”€â”€ mermaid.py              # workflow_dict_to_mermaid (Mermaid flowchart generation)
â”‚   â”‚
â”‚   â””â”€â”€ analysis/                   # Static graph analysis (Phase 2)
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ analyzer.py             # GraphAnalyzer.analyze â†’ ExecutionModel
â”‚       â”œâ”€â”€ digraph.py              # DirectedGraph from WorkflowGraph
â”‚       â”œâ”€â”€ control_flow.py         # Tarjan SCC, cycle detection, graph shape
â”‚       â”œâ”€â”€ metrics.py              # Structural metrics (counts, paths, branching)
â”‚       â”œâ”€â”€ node_annotation.py      # Per-node semantic annotation from AST
â”‚       â””â”€â”€ structural_risk.py      # Risk detection (unreachable, dead-ends, non-terminating)
â”‚   â”‚
â”‚   â”œâ”€â”€ estimation/                  # Token estimation (Phase 3)
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ data_model.py           # NodeTokenSignature, ModelProfile, CostEnvelope, WorkflowEstimate
â”‚       â”œâ”€â”€ serializer.py           # workflow_estimate_to_dict (schema 3.0)
â”‚       â”œâ”€â”€ prompt_detection.py    # AST-based prompt string detection
â”‚       â”œâ”€â”€ propagation.py          # Token propagation with topological traversal
â”‚       â”œâ”€â”€ loop_amplification.py  # Loop amplification using DetectedCycle data
â”‚       â”œâ”€â”€ branch_envelope.py     # Branch envelope computation for conditional paths
â”‚       â”œâ”€â”€ aggregation.py         # Workflow-level envelope aggregation
â”‚       â”œâ”€â”€ token_modeler.py       # TokenModeler class orchestrating the pipeline
â”‚       â””â”€â”€ profile_loader.py      # YAML profile loading and defaults
â”‚   â”‚
â”‚   â””â”€â”€ cli.py                       # CLI command interface (noctyl estimate)
â”‚
â”œâ”€â”€ tests/                          # 297 tests (pytest)
â”‚   â”œâ”€â”€ fixtures/golden/            # 8 canonical LangGraph fixture files
â”‚   â”œâ”€â”€ test_analysis.py            # Phase 2 analysis module tests
â”‚   â”œâ”€â”€ test_execution_model.py     # ExecutionModel serialization & immutability tests
â”‚   â”œâ”€â”€ test_estimation_model.py    # Phase 3 estimation data model & serializer tests
â”‚   â”œâ”€â”€ test_golden.py              # Golden fixture integration tests
â”‚   â”œâ”€â”€ test_golden_mermaid.py      # Mermaid generation for golden fixtures
â”‚   â”œâ”€â”€ test_ingestion_integration.py  # Full pipeline integration tests
â”‚   â”œâ”€â”€ test_receiver_resolution.py # Alias map & receiver resolution tests
â”‚   â”œâ”€â”€ test_graph_schema.py        # WorkflowGraph schema & serialization tests
â”‚   â”œâ”€â”€ test_mermaid.py             # Mermaid diagram generation tests
â”‚   â”œâ”€â”€ test_langgraph_detector.py  # LangGraph detection tests
â”‚   â”œâ”€â”€ test_stategraph_tracker.py  # StateGraph tracking tests
â”‚   â”œâ”€â”€ test_node_extractor.py      # Node extraction tests
â”‚   â”œâ”€â”€ test_edge_extractor.py      # Edge extraction tests
â”‚   â”œâ”€â”€ test_conditional_edges.py   # Conditional edge extraction tests
â”‚   â”œâ”€â”€ test_entry_point.py         # Entry point detection tests
â”‚   â”œâ”€â”€ test_repo_scanner.py        # File discovery tests
â”‚   â”œâ”€â”€ test_example_multi_agent.py # Multi-agent example tests
â”‚   â”œâ”€â”€ test_estimation_model.py    # Phase 3 data model & serializer tests
â”‚   â”œâ”€â”€ test_prompt_detection.py    # Phase 3 prompt detection & token signature tests
â”‚   â”œâ”€â”€ test_propagation.py         # Phase 3 token propagation tests
â”‚   â”œâ”€â”€ test_loop_amplification.py  # Phase 3 loop amplification tests
â”‚   â”œâ”€â”€ test_branch_envelope.py    # Phase 3 branch envelope tests
â”‚   â”œâ”€â”€ test_aggregation.py         # Phase 3 workflow aggregation tests
â”‚   â”œâ”€â”€ test_token_modeler.py       # Phase 3 TokenModeler integration tests
â”‚   â”œâ”€â”€ test_profile_loader.py       # Phase 3 profile loader tests
â”‚   â”œâ”€â”€ test_pipeline_integration.py  # Phase 3 pipeline integration tests
â”‚   â””â”€â”€ test_cli.py                  # CLI tests
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ flow-diagrams.md            # Pipeline & architecture Mermaid diagrams
â”‚   â””â”€â”€ phase/
â”‚       â”œâ”€â”€ phase1-scope.md         # Phase 1 scope & design
â”‚       â”œâ”€â”€ phase2.md               # Phase 2 design & implementation status
â”‚       â””â”€â”€ phase3.md               # Phase 3 design & implementation status
â”‚
â””â”€â”€ .github/
    â””â”€â”€ ISSUE_TEMPLATE/             # Phase task issue templates
```

---

## Status

**Phase 1** (LangGraph ingestion pipeline) â€” Implemented and tested.
**Phase 2** (Static graph analysis: control-flow, metrics, annotations, risks) â€” Implemented and tested.
**Phase 3** (Static token estimation) â€” In progress.
  - **Task 1** (Data model and schema 3.0 serializer) â€” Implemented and tested âœ“
  - **Task 2** (Prompt size detection) â€” Implemented and tested âœ“
  - **Task 3** (TokenModeler: propagation, loops, branches, aggregation) â€” Implemented and tested âœ“
  - **Task 4** (Pipeline integration & CLI) â€” Implemented and tested âœ“

443+ tests across 25 test files, all passing. APIs and behavior may evolve as new phases are added.

---

*Noctyl â€” know your token usage before you run.*
